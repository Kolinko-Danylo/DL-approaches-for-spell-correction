{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_with_attention(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6LLbz8mJMmY",
        "colab_type": "code",
        "outputId": "6a987e8f-12ca-4943-c9cb-20e28f52c64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "!pip3 install bpemb\n",
        "!pip3 install --force-reinstall nlpaug"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bpemb\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb) (1.17.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bpemb) (4.28.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from bpemb) (3.6.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2.8)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.3.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.9.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.12.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (1.10.27)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (2.49.0)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.27 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (1.13.27)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.27->boto3->smart-open>=1.2.1->gensim->bpemb) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.27->boto3->smart-open>=1.2.1->gensim->bpemb) (0.15.2)\n",
            "Installing collected packages: sentencepiece, bpemb\n",
            "Successfully installed bpemb-0.3.0 sentencepiece-0.1.83\n",
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/45/ce353d60920cabe773de35ee8dac0989659c055540fa50eb0f6ac774e6f0/nlpaug-0.0.10-py3-none-any.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 4.7MB/s \n",
            "\u001b[?25hInstalling collected packages: nlpaug\n",
            "Successfully installed nlpaug-0.0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFdtxnGsoP4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import math\n",
        "import socket\n",
        "hostname = socket.gethostname()\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence#, masked_cross_entropy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_uD6M3MsRAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bpemb import BPEmb\n",
        "import textwrap\n",
        "import nlpaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGa5R1cxr5gh",
        "colab_type": "code",
        "outputId": "07b459af-e257-4c7b-9a7c-62ac2852050a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "bpemb_en = BPEmb(lang=\"en\", dim=50, vs=1000, add_pad_emb=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs1000.model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 251221/251221 [00:00<00:00, 441631.98B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs1000.d50.w2v.bin.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 190477/190477 [00:00<00:00, 458479.78B/s]\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swVR24zW7kGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSg_YFsyr5mX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# open text file and read in data as `text`\n",
        "with open('big.txt', 'r') as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8mZA6pdfaM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(arr, n_labels):\n",
        "    \n",
        "    # Initialize the the encoded array\n",
        "    one_hot = np.zeros((arr.size, n_labels), dtype=np.float32)\n",
        "    \n",
        "    # Fill the appropriate elements with ones\n",
        "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
        "    \n",
        "    # Finally reshape it to get back to the original array\n",
        "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
        "    \n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q5Woi5-6Xgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nlpaug.augmenter.char as nac\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URvJKox6YznH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_encodes(arr, seq_length, use_aug=False):\n",
        "  if use_aug:\n",
        "    aug_rr = nac.KeyboardAug(aug_char_min=0, aug_char_max=None, aug_char_p=0.4, aug_word_p=0.4, aug_word_min=0, aug_word_max=arr.size//3, special_char=False)\n",
        "    \n",
        "    augmented_data = list(map(lambda x: aug_rr.augment(x), arr.ravel()))\n",
        "    arr = np.array(augmented_data).reshape(arr.shape)\n",
        "  flat_arr = arr.ravel()\n",
        "\n",
        "  def padded_encode(x):\n",
        "    k = np.full((seq_length,), bpemb_en.vs)\n",
        "    enc = np.array(bpemb_en.encode_ids(x))\n",
        "    k[:enc.size] = enc\n",
        "\n",
        "\n",
        "    return enc.size, k\n",
        "\n",
        "  res_arr = np.empty((*flat_arr.shape, seq_length), dtype=\"int32\")\n",
        "  len_vec = np.empty( (arr.shape[0]))\n",
        "  for i in range(flat_arr.size):\n",
        "\n",
        "    res = padded_encode(flat_arr[i])  \n",
        "    res_arr[i] = res[1]\n",
        "    len_vec[i] = res[0]\n",
        "\n",
        "  if not use_aug:\n",
        "    res_arr = np.insert(res_arr, 0, 1, 1)\n",
        "  len_vec, perm_idx = torch.from_numpy(len_vec).sort(0, descending=True)\n",
        "  res_arr = res_arr[perm_idx]\n",
        "\n",
        "  leng, res = len_vec, one_hot_encode(res_arr, bpemb_en.vs + 1)\n",
        "\n",
        "  leng += (1 if not use_aug else 0)\n",
        "  leng, res = leng, torch.from_numpy(res)\n",
        "\n",
        "  return leng, res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xAru18_FBm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(arr, batch_size, seq_length):\n",
        "    '''Create a generator that returns batches of size\n",
        "       batch_size x seq_length from arr.\n",
        "       \n",
        "       Arguments\n",
        "       ---------\n",
        "       arr: Array you want to make batches from\n",
        "       batch_size: Batch size, the number of sequences per batch\n",
        "       seq_length: Number of encoded chars in a sequence\n",
        "    '''\n",
        "    \n",
        "    # total number of batches we can make\n",
        "    n_batches = len(arr)//batch_size\n",
        "    \n",
        "    # Keep only enough characters to make full batches\n",
        "    arr = arr[:n_batches * batch_size]    \n",
        "\n",
        "  \n",
        "\n",
        "    # Reshape into batch_size rows\n",
        "    arr = arr.reshape((batch_size, -1))\n",
        "    # iterate through the array, one sequence at a time\n",
        "    for n in range(0, arr.shape[1]):\n",
        "        # The features\n",
        "        base = arr[:, n:n+1]\n",
        "        # y = np.vectorize(get_int)(base)\n",
        "\n",
        "        x = base.copy()\n",
        "        # y = one_hot_encode(y, len(words))\n",
        "        lengths_x, x = get_encodes(x, seq_length, use_aug=True)\n",
        "        lengths_y, y = get_encodes(base, seq_length)\n",
        "        \n",
        "        yield lengths_x, x, lengths_y, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOGrQItGFBlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "arr = np.array(textwrap.wrap(text=text, width=5))\n",
        "\n",
        "batches = get_batches(arr, 2, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOHqalBXFBja",
        "colab_type": "code",
        "outputId": "619892b3-0973-4aad-ae2f-20f05266eb50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lengths_x, x, lengths_y, y = next(batches)\n",
        "x.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 5, 1001])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrc0kTuEZ8VW",
        "colab_type": "text"
      },
      "source": [
        "### Hide\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cze_2BXWFBfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        self.gru = nn.GRU(input_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True, batch_first=True)\n",
        "        \n",
        "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
        "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(input_seqs, input_lengths, batch_first=True)\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True) # unpack (back to padded)\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
        "        return outputs, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkX9fH5lYTV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        \n",
        "        self.method = method\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        if self.method == 'general':\n",
        "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "\n",
        "        elif self.method == 'concat':\n",
        "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        max_len = encoder_outputs.size(1)\n",
        "        this_batch_size = encoder_outputs.size(0)\n",
        "\n",
        "        # Create variable to store attention energies\n",
        "        attn_energies = torch.zeros(this_batch_size, max_len) # B x S\n",
        "\n",
        "\n",
        "        attn_energies = attn_energies.cuda()\n",
        "\n",
        "        # For each batch of encoder outputs\n",
        "        for b in range(this_batch_size):\n",
        "            # Calculate energy for each encoder output\n",
        "            for i in range(max_len):\n",
        "                attn_energies[b, i] = self.score(hidden[b, :].squeeze(0), encoder_outputs[b, i])\n",
        "\n",
        "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
        "        return F.softmax(attn_energies).unsqueeze(1)\n",
        "    \n",
        "    def score(self, hidden, encoder_output):\n",
        "        \n",
        "        if self.method == 'dot':\n",
        "            energy = hidden.dot(encoder_output)\n",
        "            return energy\n",
        "        \n",
        "        elif self.method == 'general':\n",
        "            energy = self.attn(encoder_output)\n",
        "            energy = hidden.dot(energy)\n",
        "            return energy\n",
        "        \n",
        "        elif self.method == 'concat':\n",
        "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
        "            energy = self.v.dot(energy)\n",
        "            return energy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkNv2CgzYWGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, input_size, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(input_size, hidden_size, n_layers, dropout=dropout, batch_first=True)\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "        # Choose attention model\n",
        "        if attn_model != 'none':\n",
        "            self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
        "\n",
        "        rnn_output, hidden = self.gru(input_seq, last_hidden)\n",
        "\n",
        "        # Calculate attention from current RNN state and all encoder outputs;\n",
        "        # apply to encoder outputs to get weighted average\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        context = attn_weights.bmm(encoder_outputs) # B x S=1 x N\n",
        "\n",
        "        # Attentional vector using the RNN hidden state and context vector\n",
        "        # concatenated together (Luong eq. 5)\n",
        "        rnn_output = rnn_output.squeeze(1) # S=1 x B x N -> B x N\n",
        "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
        "\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = F.tanh(self.concat(concat_input))\n",
        "\n",
        "        # Finally predict next token (Luong eq. 6, without softmax)\n",
        "        output = F.log_softmax(self.out(concat_output))\n",
        "\n",
        "        # Return final output, hidden state, and attention weights (for visualization)\n",
        "        return output, hidden, attn_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W89ia-wjRSMH",
        "colab_type": "text"
      },
      "source": [
        "### Imp\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAklApHnxkCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(Y_hat, Y):\n",
        "        # TRICK 3 ********************************\n",
        "        # before we calculate the negative log likelihood, we need to mask out the activations\n",
        "        # this means we don't want to take into account padded items in the output vector\n",
        "        # simplest way to think about this is to flatten ALL sequences into a REALLY long sequence\n",
        "        # and calculate the loss on that.\n",
        "\n",
        "        # flatten all the labels\n",
        "        Y = Y.view(-1)\n",
        "\n",
        "        # flatten all predictions\n",
        "        Y_hat = Y_hat.view(-1, Y_hat.size(-1))\n",
        "\n",
        "        # create a mask by filtering out all tokens that ARE NOT the padding token\n",
        "        tag_pad_token = 1000\n",
        "        mask = (Y < tag_pad_token).float()\n",
        "\n",
        "        # count how many tokens we have\n",
        "        nb_tokens = int(torch.sum(mask).item())\n",
        "\n",
        "        # pick the values for the label and zero out the rest with the mask\n",
        "        Y_hat = Y_hat[range(Y_hat.shape[0]), Y] * mask\n",
        "\n",
        "        # compute cross entropy loss which ignores all <PAD> tokens\n",
        "        ce_loss = -torch.sum(Y_hat) / nb_tokens\n",
        "\n",
        "        return ce_loss\n",
        "def cus_loss():\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kh1hGNpUl7Bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(encoder, decoder, data, epochs=10, batch_size=30, seq_length=500, hidden_size=1000, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "    ''' Training a network \n",
        "    \n",
        "        Arguments\n",
        "        ---------\n",
        "        \n",
        "        net: CharRNN network\n",
        "        data: text data to train the network\n",
        "        epochs: Number of epochs to train\n",
        "        batch_size: Number of mini-sequences per mini-batch, aka batch size\n",
        "        seq_length: Number of character steps per mini-batch\n",
        "        lr: learning rate\n",
        "        clip: gradient clipping\n",
        "        val_frac: Fraction of data to hold out for validation\n",
        "        print_every: Number of steps for printing training and validation loss\n",
        "    \n",
        "    '''\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    \n",
        "    opt1 = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
        "    opt2 = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "\n",
        "    criterion = cus_loss()\n",
        "\n",
        "\n",
        "    # create training and validation data\n",
        "    val_idx = int(len(data)*(1-val_frac))\n",
        "    data, val_data = data[:val_idx], data[val_idx:]\n",
        "    \n",
        "    decoder.cuda()\n",
        "    encoder.cuda()\n",
        "    \n",
        "    counter = 0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        # initialize hidden state\n",
        "        h = None\n",
        "\n",
        "        for lenx, x, leny, y in get_batches(data, batch_size=batch_size, seq_length=seq_length):\n",
        "          try:\n",
        "            counter += 1\n",
        "                        # One-hot encode our data and make them Torch tensors\n",
        "            lenx, leny = lenx.cuda(), leny.cuda()\n",
        "            inputs, targets = x.cuda(), y.cuda()\n",
        "\n",
        "            # Creating new variables for the hidden state, otherwise\n",
        "            # we'd backprop through the entire training history\n",
        "            h = None\n",
        "\n",
        "            # zero accumulated gradients\n",
        "            encoder.zero_grad()\n",
        "            decoder.zero_grad()\n",
        "            \n",
        "            max_target_length = int(max(leny).item())\n",
        "            decoder_input = targets[:, :1]\n",
        "\n",
        "            all_decoder_outputs = torch.zeros(batch_size, max_target_length, decoder.output_size)\n",
        "\n",
        "            decoder_input = decoder_input.cuda()\n",
        "            all_decoder_outputs = all_decoder_outputs.cuda()\n",
        "\n",
        "            # Run through decoder one time step at a time\n",
        "            encoder_outputs, encoder_hidden = encoder(inputs, lenx, h)\n",
        "\n",
        "            decoder_hidden = encoder_hidden[:decoder.n_layers].cuda()\n",
        "\n",
        "            for t in range(max_target_length):\n",
        "                decoder_output, decoder_hidden, decoder_attn = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "                all_decoder_outputs[:, t] = decoder_output\n",
        "                decoder_input = targets[:, t+1].unsqueeze(1) # Next input is current target\n",
        "            # get the output from the model\n",
        "            # h_dec = encoder_outputs\n",
        "            # print(\"Encoder_hidden: \", encoder_hidden.size())\n",
        "            # out, h_dec = decoder(targets[:, :-1], encoder_hidden[:decoder.n_layers], h_dec)\n",
        "            out = all_decoder_outputs\n",
        "            targets = targets[:, :out.size(1)]\n",
        "            tar = targets.argmax(2)\n",
        "            tar = tar.view(tar.size(0)*tar.size(1))\n",
        "            cur = out.view(out.size(0)*out.size(1), -1)\n",
        "\n",
        "            loss = criterion(cur, tar)\n",
        "            training_loss.append(loss.item())\n",
        "\n",
        "\n",
        "            # calculate the loss and perform backprop\n",
        "            # loss = criterion(output, targets.view(batch_size*seq_length).long())\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "            nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "            opt2.step()\n",
        "            opt1.step()\n",
        "            \n",
        "            \n",
        "            # loss stats\n",
        "            if counter % print_every == 0:\n",
        "                    # Get validation loss\n",
        "                val_h = None\n",
        "                val_losses = []\n",
        "                val_acc = []\n",
        "                encoder.eval()\n",
        "                decoder.eval()\n",
        "\n",
        "                for lenx, x, leny, y in get_batches(val_data, batch_size=batch_size, seq_length=seq_length):\n",
        "\n",
        "                        # One-hot encode our data and make them Torch tensors\n",
        "                        \n",
        "                        # Creating new variables for the hidden state, otherwise\n",
        "                        # we'd backprop through the entire training history\n",
        "                    val_h = None\n",
        "                        \n",
        "                    inputs, targets = x, y\n",
        "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
        "                    lenx, leny = lenx.cuda(), leny.cuda()\n",
        "                        \n",
        "\n",
        "                    encoder_outputs, encoder_hidden = encoder(inputs, lenx, val_h)\n",
        "\n",
        "                    max_target_length = int(max(leny).item())\n",
        "                    decoder_input = targets[:, :1]\n",
        "\n",
        "                    all_decoder_outputs = torch.zeros(batch_size, max_target_length, decoder.output_size)\n",
        "\n",
        "                    decoder_input = decoder_input.cuda()\n",
        "                    all_decoder_outputs = all_decoder_outputs.cuda()\n",
        "\n",
        "                    # Run through decoder one time step at a time\n",
        "                    encoder_outputs, encoder_hidden = encoder(inputs, lenx, h)\n",
        "\n",
        "                    decoder_hidden = encoder_hidden[:decoder.n_layers].cuda()\n",
        "\n",
        "                    for t in range(max_target_length - 1):\n",
        "                        decoder_output, decoder_hidden, decoder_attn = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "\n",
        "                        all_decoder_outputs[:, t] = decoder_output\n",
        "                        decoder_input = targets[:, t+1].unsqueeze(1) # Next input is current target\n",
        "                    \n",
        "                    # get the output from the model\n",
        "                    # h_dec = encoder_outputs\n",
        "                    # print(\"Encoder_hidden: \", encoder_hidden.size())\n",
        "                    # out, h_dec = decoder(targets[:, :-1], encoder_hidden[:decoder.n_layers], h_dec)\n",
        "                    out = all_decoder_outputs\n",
        "                    targets = targets[:, :out.size(1)]\n",
        "                    # h_dec = encoder_outputs\n",
        "\n",
        "                    # out, h_dec = decoder(targets[:, :-1], encoder_hidden[:decoder.n_layers], h_dec)\n",
        "                    tar = targets.argmax(2)\n",
        "                    tar = tar.view(tar.size(0)*tar.size(1))\n",
        "                    cur = out.view(out.size(0)*out.size(1), -1)\n",
        "                    val_loss = criterion(cur, tar)\n",
        "              \n",
        "                    validation_loss.append(val_loss.item())\n",
        "                    val_losses.append(val_loss.item())\n",
        "                    output = cur\n",
        "                    ind = min(len(validation_loss), 10)\n",
        "                    acc_output = output.cpu().detach()\n",
        "\n",
        "                    Y = tar.cpu().view(-1)\n",
        "\n",
        "                    Y_hat = acc_output.argmax(1)\n",
        "                    Y_hat = Y_hat.view(-1)\n",
        "\n",
        "                    tag_pad_token = 1000\n",
        "                    mask = (Y < tag_pad_token).float()\n",
        "\n",
        "                    nb_tokens = int(torch.sum(mask).item())\n",
        "\n",
        "                    current_accuracy =  (np.equal(Y_hat.numpy().astype(\"int32\"), Y.numpy()) * mask.numpy()).sum()\n",
        "\n",
        "                    div = nb_tokens\n",
        "                    val_acc.append(current_accuracy/(div))\n",
        "                    validation_accuracy.append(current_accuracy/(div))\n",
        "                    \n",
        "\n",
        "                    if min(validation_loss[-ind:]) != min(validation_loss): break\n",
        "                    \n",
        "                encoder.train() # reset to train mode after iterationg through validation data\n",
        "                decoder.train()\n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)),\n",
        "                      \"Val Accuracy: {:.4f}\".format(np.mean(val_acc)))\n",
        "          except Exception as ex:\n",
        "            print(str(e))\n",
        "            raise e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkA-zvcdo5wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = bpemb_en.vs + 1\n",
        "hidden_size = 300\n",
        "decoder = LuongAttnDecoderRNN('general', CLASSES, hidden_size, CLASSES, n_layers=2)\n",
        "\n",
        "encoder = EncoderRNN(CLASSES, hidden_size, n_layers=2)\n",
        "\n",
        "sl = 40\n",
        "data = np.array(textwrap.wrap(text=text, width=sl))\n",
        "\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "validation_accuracy = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAFmXDlM13BH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "dfe5dee2-3960-43a1-c2b3-eee61158d40d"
      },
      "source": [
        "train(encoder, decoder, data, epochs=10, batch_size=10, seq_length=sl, hidden_size=hidden_size, lr=0.001, clip=5, val_frac=0.1, print_every=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/10... Step: 10... Loss: 0.2724... Val Loss: 0.2802 Val Accuracy: 0.9379\n",
            "Epoch: 1/10... Step: 20... Loss: 0.3358... Val Loss: 0.2982 Val Accuracy: 0.9448\n",
            "Epoch: 1/10... Step: 30... Loss: 0.3590... Val Loss: 0.3413 Val Accuracy: 0.9241\n",
            "Epoch: 1/10... Step: 40... Loss: 0.3070... Val Loss: 0.3563 Val Accuracy: 0.9172\n",
            "Epoch: 1/10... Step: 50... Loss: 0.2360... Val Loss: 0.3612 Val Accuracy: 0.9448\n",
            "Epoch: 1/10... Step: 60... Loss: 0.2456... Val Loss: 0.3641 Val Accuracy: 0.9379\n",
            "Epoch: 1/10... Step: 70... Loss: 0.1803... Val Loss: 0.3638 Val Accuracy: 0.9379\n",
            "Epoch: 1/10... Step: 80... Loss: 0.2267... Val Loss: 0.3477 Val Accuracy: 0.9379\n",
            "Epoch: 1/10... Step: 90... Loss: 0.2581... Val Loss: 0.3439 Val Accuracy: 0.9448\n",
            "Epoch: 1/10... Step: 100... Loss: 0.1819... Val Loss: 0.3293 Val Accuracy: 0.9448\n",
            "Epoch: 1/10... Step: 110... Loss: 0.2353... Val Loss: 0.3378 Val Accuracy: 0.9379\n",
            "Epoch: 1/10... Step: 120... Loss: 0.2485... Val Loss: 0.3091 Val Accuracy: 0.9379\n",
            "Epoch: 1/10... Step: 130... Loss: 0.1997... Val Loss: 0.2679 Val Accuracy: 0.9517\n",
            "Epoch: 1/10... Step: 140... Loss: 0.1887... Val Loss: 0.2505 Val Accuracy: 0.9586\n",
            "Epoch: 1/10... Step: 150... Loss: 0.1539... Val Loss: 0.2248 Val Accuracy: 0.9586\n",
            "Epoch: 1/10... Step: 160... Loss: 0.3352... Val Loss: 0.2097 Val Accuracy: 0.9586\n",
            "Epoch: 1/10... Step: 170... Loss: 0.2323... Val Loss: 0.2183 Val Accuracy: 0.9517\n",
            "Epoch: 1/10... Step: 180... Loss: 0.1106... Val Loss: 0.2151 Val Accuracy: 0.9586\n",
            "Epoch: 1/10... Step: 190... Loss: 0.2285... Val Loss: 0.2105 Val Accuracy: 0.9586\n",
            "Epoch: 1/10... Step: 200... Loss: 0.3053... Val Loss: 0.2087 Val Accuracy: 0.9586\n",
            "Epoch: 1/10... Step: 210... Loss: 0.1805... Val Loss: 0.2207 Val Accuracy: 0.9517\n",
            "Epoch: 1/10... Step: 220... Loss: 0.1700... Val Loss: 0.2170 Val Accuracy: 0.9517\n",
            "Epoch: 1/10... Step: 230... Loss: 0.2278... Val Loss: 0.2106 Val Accuracy: 0.9655\n",
            "Epoch: 1/10... Step: 240... Loss: 0.1691... Val Loss: 0.1887 Val Accuracy: 0.9724\n",
            "Epoch: 1/10... Step: 250... Loss: 0.1258... Val Loss: 0.1885 Val Accuracy: 0.9655\n",
            "Epoch: 1/10... Step: 260... Loss: 0.1756... Val Loss: 0.1337 Val Accuracy: 0.9716\n",
            "Epoch: 1/10... Step: 270... Loss: 0.1689... Val Loss: 0.1414 Val Accuracy: 0.9793\n",
            "Epoch: 1/10... Step: 280... Loss: 0.1336... Val Loss: 0.1466 Val Accuracy: 0.9793\n",
            "Epoch: 1/10... Step: 290... Loss: 0.2175... Val Loss: 0.1379 Val Accuracy: 0.9655\n",
            "Epoch: 1/10... Step: 300... Loss: 0.1264... Val Loss: 0.1493 Val Accuracy: 0.9655\n",
            "Epoch: 1/10... Step: 310... Loss: 0.1735... Val Loss: 0.1479 Val Accuracy: 0.9724\n",
            "Epoch: 1/10... Step: 320... Loss: 0.1541... Val Loss: 0.1456 Val Accuracy: 0.9586\n",
            "Epoch: 1/10... Step: 330... Loss: 0.1655... Val Loss: 0.1248 Val Accuracy: 0.9724\n",
            "Epoch: 1/10... Step: 340... Loss: 0.2194... Val Loss: 0.1150 Val Accuracy: 0.9793\n",
            "Epoch: 1/10... Step: 350... Loss: 0.0885... Val Loss: 0.1210 Val Accuracy: 0.9793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk2Fi0p39o4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'seq2seq_encoder_20_epoch.net'\n",
        "torch.save(encoder.state_dict(), model_name)\n",
        "\n",
        "\n",
        "model1_name = 'seq2seq_decoder_20_epoch.net'\n",
        "torch.save(decoder.state_dict(), model1_name)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSLR1-0WxUnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, word, h=None, top_k=None):\n",
        "        ''' Given a character, predict the next character.\n",
        "            Returns the predicted character and the hidden state.\n",
        "        '''\n",
        "        \n",
        "        x = np.array([word])\n",
        "        x = get_encodes(x).reshape(1, 1, -1)\n",
        "        inputs = torch.from_numpy(x)\n",
        "        print(inputs.shape)\n",
        "        \n",
        "        if(train_on_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "        \n",
        "        # detach hidden state from history\n",
        "        h = tuple([each.data for each in h])\n",
        "        # get the output of the model\n",
        "        out, h = net(inputs, h)\n",
        "\n",
        "        # get the character probabilities\n",
        "        p = F.softmax(out, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "        \n",
        "        return p, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX2LxHzkxUyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(encoder, decoder, sentence='The', top_k=None):\n",
        "    lst_res = []\n",
        "    encoder.eval()\n",
        "    decoder.eval() # eval mode\n",
        "    \n",
        "        \n",
        "    h = None\n",
        "    length, inputs = get_encodes(np.array(sentence[:100]), seq_length=80)\n",
        "    \n",
        "    inputs, length = inputs.cuda(), length.cuda()\n",
        "    res, h = encoder(inputs, length, h)\n",
        "    while True:\n",
        "      h_dec = res\n",
        "      zero_s = np.zeros((100, 1, 10000))\n",
        "      zero_s[:, :, 0] = 1\n",
        "      print( h[:decoder.n_layers].shape, h_dec.shape)\n",
        "      out, h_dec = decoder(zero_s, h[:decoder.n_layers], h_dec)\n",
        "\n",
        "      tar = inputs.argmax(1)\n",
        "      tar = tar.view(tar.size(0)*tar.size(1))\n",
        "      cur = out.view(out.size(0)*out.size(1), -1)\n",
        "      val_loss = criterion(cur, tar)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ktcGADTxUw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample(encoder, decoder, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwOR8EgFxUuy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M-MFc12xUsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsV2tMfUxUip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}